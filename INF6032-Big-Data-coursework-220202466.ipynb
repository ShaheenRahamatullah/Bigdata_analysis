{"cells":[{"cell_type":"code","source":["#import pyspark and create spark session\nimport pyspark\nfrom pyspark.sql import SparkSession\n\n#create spark session\nspark = SparkSession.builder.getOrCreate()\nfrom pyspark.sql import functions as F"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"a3deb654-2b9b-4175-ab40-c73f2ceb8bfb","inputWidgets":{},"title":"#import pyspark libraries and create spark session"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#dbutils.fs.mv('/FileStore/tables/skill2vec_50K_csv.gz', '/FileStore/tables/skill2vec_50K.csv.gz')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"49303267-cc0a-4da5-801a-b5016894fd7b","inputWidgets":{},"title":"#To rename the file with the given file name in the coursework"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#read the input file into a Dataframe\njd = spark.read.csv('/FileStore/tables/skill2vec_50K.csv.gz')\n\n#Sanity check - Verify if the data is loaded correctly\nprint(\"number of records:\" ,jd.count())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"2fe7363d-d623-4ef2-99c8-3b2defbdf289","inputWidgets":{},"title":"#Read the input file into a Dataframe:"}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["number of records: 50000\n"]}],"execution_count":0},{"cell_type":"code","source":["#create a dataframe with column 0 - identifier and column 1 - the skills list\njd_columns = jd.columns[1:]\njdlistDF = jd.select(jd.columns[0], F.array( jd_columns ).alias( 'jd_skills_list') )\n\n#rename the first column as jd_identifier\njdlistDF = jdlistDF.withColumnRenamed('_c0','jd_identifier')\n\n#remove all the nulls and create and new column with only data\njd_non_nullDF = jdlistDF.withColumn ( 'jd_skills_list_not_null' , F.array_except('jd_skills_list' , F.array(F.lit(None))))\n\n#count the number of skills listed in the job description and add a column with the count of skills\njd_non_nullDF_count = jd_non_nullDF.withColumn ( 'Num_skills' , F.size( 'jd_skills_list_not_null' ) )"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"00e4f688-114a-4b2f-91b5-1fc25dbbc1c1","inputWidgets":{},"title":"#Preprocessing"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Q1: sanity check: to see if there are any null values in the jd_identifier\nprint(\"Number of rows in job identifier is with null:\", jd_non_nullDF.where(jd_non_nullDF.jd_identifier == 'null').count())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"e0852402-7ecb-4dc6-ad2f-27b2b9915dfc","inputWidgets":{},"title":"Question 1: sanity check: to check if there are any null values in the jd_identifier"}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Number of rows in job identifier is with null: 0\n"]}],"execution_count":0},{"cell_type":"code","source":["#Question 1:\n#Programmatically confirm that the number of job descriptions is as expected (i.e. that\n#there are 50,000 distinct job numbers / identifers / description in the skill2vec 50K dataset).\nprint(\"Distinct number of job descriptions: \", jd_non_nullDF.select('jd_identifier').distinct().count())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"e681f836-9f6a-46af-b1d1-09e86f39a895","inputWidgets":{},"title":"Question 1: Programmatically confirm that the number of job descriptions is as expected"}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Distinct number of job descriptions:  50000\n"]}],"execution_count":0},{"cell_type":"code","source":["#Q2 - Sanity check: Every JD identifier has at least one skill\nprint(\"Number of jobs without any skills :\", jd_non_nullDF_count.where(jd_non_nullDF_count.Num_skills < 1).count() )"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"aec467df-da95-49c5-9aef-cab4fc4d679c","inputWidgets":{},"title":"Question 2: Sanity check to see if there are any job description without any skills mentioned in it"}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Number of jobs without any skills : 0\n"]}],"execution_count":0},{"cell_type":"code","source":["#Question 2:\n#Work out the frequencies with which distinct skills are mentioned in job descriptions,\n#and present the top 10 (in order of decreasing frequency) skills in your report, alongside\n#the frequency of each across the entire dataset. I.e. if your dataset consists of the\n#following:\n\n#Explode the array into individual records\nind_jd_DF = jd_non_nullDF_count.withColumn(\"Skills\", F.explode(F.col('jd_skills_list_not_null')))\n\n#Groupby to find the count of individual job skills\nind_jd_count_DF = ind_jd_DF.groupBy('Skills').count()\n\n#rename column name from count to Freq\nind_jd_count_DF = ind_jd_count_DF.withColumnRenamed('count','Freq') \n\n#Display the top 10 skills with highest frequency\nind_jd_count_DF.sort('Freq', ascending=False).show(10,truncate = False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"89af66b0-9ae2-42cb-be00-505668d58552","inputWidgets":{},"title":"Question 2: To display the top 10 skills listed frequently"}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+--------------------+----+\n|Skills              |Freq|\n+--------------------+----+\n|Java                |1911|\n|Javascript          |1770|\n|Sales               |1705|\n|Business Development|1545|\n|Web Technologies    |1313|\n|Communication Skills|1305|\n|development         |1238|\n|Marketing           |1184|\n|Finance             |1078|\n|HTML                |1067|\n+--------------------+----+\nonly showing top 10 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#Question 3:\n#Find the 5 most frequent numbers of skills in JDs across the dataset. I.e. given the\n#example with JD1, JD2 and JD3 above, the expected result would be:\n\n#Group by on number of skills to find the count of jobs that have the same number of skills\nnum_skills_count = jd_non_nullDF_count.groupBy('Num_skills').count()\n\n#Show the top 5 most frequent number of skills listed in JD\nnum_skills_count.sort('count', ascending=False).show(5,truncate = False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"0700e51c-bea8-4ee4-ba83-81c59b0909e7","inputWidgets":{},"title":"#Question 3: Find the 5 most frequent numbers of skills in JD"}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+----------+-----+\n|Num_skills|count|\n+----------+-----+\n|10        |10477|\n|5         |3432 |\n|6         |3405 |\n|1         |3386 |\n|7         |3345 |\n+----------+-----+\nonly showing top 5 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#Question 4:\n#So far, you’ve explored the dataset in its original form. Check how the distribution of\n#the frequencies with which distinct skills are mentioned in JDs changes if you lower case\n#all the skills. As in question 2, present the top 10 (in order of decreasing frequency)\n#skills in your report.\n\n#Create a new column with individual columns in lower case\nind_jd_lower_DF = ind_jd_DF.withColumn(\"Skills_lower\", F.lower(F.col('Skills')))\n\n#groupby to find the count of the jobs in lower case\nind_jd_lower_count_DF = ind_jd_lower_DF.groupBy('Skills_lower').count()\n\n#Display the top 10 skills\nind_jd_lower_count_DF.sort('count', ascending=False).show(10,truncate = False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"ff251d32-a5c9-49fc-a368-92b9b3bb4e61","inputWidgets":{},"title":"#Question 4: Present the top 10 skills after changing to lower case "}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+--------------------+-----+\n|Skills_lower        |count|\n+--------------------+-----+\n|java                |2759 |\n|javascript          |2738 |\n|sales               |2680 |\n|business development|2108 |\n|marketing           |1809 |\n|sql                 |1564 |\n|jquery              |1547 |\n|html                |1539 |\n|communication skills|1537 |\n|bpo                 |1530 |\n+--------------------+-----+\nonly showing top 10 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#dbutils.fs.mv('/FileStore/tables/TechnologySkills.txt', '/FileStore/tables/Technology_Skills.txt')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"37a9d8c2-0438-4251-a2a3-e832e50e95a9","inputWidgets":{},"title":"#Rename Technology skills with correct file name given in the coursework"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Question 5:\n#To gain some additional information about the sought after skills, you’d like to join\n#the (lower cased) skills from JDs with the skills listed in the Example column in the\n#O*NET dataset (don’t forget to lower case the example column!). Find the change in\n#the number of skills before and after the join (i.e. report the number of original skills\n#and the skills that are both in the JD dataset and the O*NET dataset { reporting two\n#separate numbers).\n\n#read the input file into a Dataframe\nTech_skills = spark.read.format('csv') \\\n   .option('header', 'true') \\\n   .option('delimiter', '\\t') \\\n   .load('dbfs:/FileStore/tables/Technology_Skills.txt')\n\n#Convert Example column to lower case\nTech_skills_lower = Tech_skills.withColumn(\"Example_lower\", F.lower(F.col('Example')))\n\n#To print the count before join\nprint(\"Count of JD skills before join:\" , ind_jd_lower_DF.select('Skills_lower').count() )\n\n#Join the 2 dataframe using skills columns\njoin_jd = ind_jd_lower_DF.join(Tech_skills_lower , ind_jd_lower_DF['Skills_lower'] == Tech_skills_lower['Example_lower'] , 'inner')\n\n#To print the count after join\nprint(\"Count of JD skills after join with Tech skills = \", join_jd.count())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"405db6f3-b401-4ee4-9203-23fb273387e8","inputWidgets":{},"title":"#Question 5: To find the count before and after the join with technical_skills"}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Count of JD skills before join: 463803\nCount of JD skills after join with Tech skills =  1101498\n"]}],"execution_count":0},{"cell_type":"code","source":["#Question 6:\n#The join you performed in Question 5 gives you access to the \\Commodity Title\" column. \n#Find the 10 most frequent \\Commodity Title\"s across all the job descriptions.\n#I.e. using the example from Question 2, the output should be:\n\n#Group by on Commodity Title\njoin_jd_count = join_jd.groupby('Commodity Title').count()\n\n#Sort on descending order and display only the top 10\njoin_jd_count.sort('count', ascending=False).show(10,truncate = False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"08d6041b-2e9d-4cec-aca2-643d52d6f601","inputWidgets":{},"title":"#Question 6: Find the 10 most frequent “Commodity Title”s across all the job descriptions."}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------------------------------------------------+------+\n|Commodity Title                                  |count |\n+-------------------------------------------------+------+\n|Object or component oriented development software|324521|\n|Web platform development software                |298754|\n|Operating system software                        |190926|\n|Development environment software                 |53013 |\n|Data base management system software             |44132 |\n|Analytical or scientific software                |33552 |\n|Web page creation and editing software           |31682 |\n|Data base user interface and query software      |29436 |\n|Spreadsheet software                             |18568 |\n|File versioning software                         |13846 |\n+-------------------------------------------------+------+\nonly showing top 10 rows\n\n"]}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"INF6032-Big-Data-coursework-220202466","dashboards":[{"elements":[],"guid":"698948e1-877b-4560-b674-4fd00667551b","layoutOption":{"stack":true,"grid":true},"version":"DashboardViewV1","nuid":"2fb78408-57cd-4659-a33d-bf4e6546185f","origId":1839984644365068,"title":"Untitled","width":1024,"globalVars":{}},{"elements":[{"elementNUID":"00e4f688-114a-4b2f-91b5-1fc25dbbc1c1","dashboardResultIndex":0,"guid":"3b0ef713-4ed9-4baf-b0a8-691aae552abe","resultIndex":null,"options":null,"position":{"x":0,"y":0,"height":6,"width":12,"z":null},"elementType":"command"}],"guid":"dff52aab-2c08-4fc6-a13c-509b854f0ffa","layoutOption":{"stack":true,"grid":true},"version":"DashboardViewV1","nuid":"d6c2859d-ee04-40ea-a04e-d46afd1d496e","origId":1839984644365069,"title":"Untitled","width":1024,"globalVars":{}}],"notebookMetadata":{"pythonIndentUnit":4,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":1013091911830742,"dataframes":["_sqldf"]}},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
